{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from datasets import load_dataset\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facabe96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614c4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf_and_get_split_documents(chunk_size=1000, chunk_overlap=120):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book or dataset into a FAISS vector store.\n",
    "    Returns: vectorstore, texts (list of Document)\n",
    "    \"\"\"\n",
    "    DB_FAISS_PATH = \"faiss_index_fusion\"\n",
    "\n",
    "    print(\"Veriseti indiriliyor: 'neural-bridge/rag-dataset-12000'...\")\n",
    "    dataset = load_dataset(\"neural-bridge/rag-dataset-12000\", split=\"train\")\n",
    "    print(\"Veriseti başarıyla indirildi.\")\n",
    "\n",
    "    # Dokümanları oluştur\n",
    "    documents = [Document(page_content=item[\"context\"]) for item in dataset]\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # FAISS index varsa yükle\n",
    "    if os.path.exists(DB_FAISS_PATH):\n",
    "        print(\"Mevcut FAISS veritabanı yükleniyor...\")\n",
    "        vectorstore = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "        return vectorstore, texts\n",
    "\n",
    "    # Yeni FAISS index oluştur\n",
    "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "    vectorstore.save_local(DB_FAISS_PATH)\n",
    "    return vectorstore, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111a51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(documents: List[Document]) -> BM25Okapi:\n",
    "    tokenized_docs = [doc.page_content.split() for doc in documents]  # basit tokenize\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    bm25.corpus_docs = documents  # fusion sırasında alignment için\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a55f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(vectorstore, bm25, query: str, k: int = 5, alpha: float = 0.5, top_k_vector: int = 100):\n",
    "    \"\"\"\n",
    "    Returns top-k documents along with BM25 and vector scores.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    query_tokens = query.split()\n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    all_docs = list(bm25.corpus_docs)\n",
    "\n",
    "    # Vector search\n",
    "    vector_results = vectorstore.similarity_search_with_score(query, k=min(top_k_vector, len(all_docs)))\n",
    "    vector_scores_dict = {doc.page_content: score for doc, score in vector_results}\n",
    "\n",
    "    # Normalize BM25\n",
    "    bm25_scores_norm = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + epsilon)\n",
    "\n",
    "    # Normalize vector (FAISS cosine similarity, yüksek = iyi)\n",
    "    vector_scores = np.array([vector_scores_dict.get(doc.page_content, 0) for doc in all_docs])\n",
    "    vector_scores_norm = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "\n",
    "    # Fusion\n",
    "    combined_scores = alpha * vector_scores_norm + (1 - alpha) * bm25_scores_norm\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "\n",
    "    # Top k doküman ve skorları\n",
    "    top_docs = []\n",
    "    for i in sorted_indices[:k]:\n",
    "        doc = all_docs[i]\n",
    "        top_docs.append({\n",
    "            \"document\": doc,\n",
    "            \"bm25_score\": bm25_scores[i],\n",
    "            \"vector_score\": vector_scores[i],\n",
    "            \"combined_score\": combined_scores[i]\n",
    "        })\n",
    "\n",
    "    return top_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af856017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veriseti indiriliyor: 'neural-bridge/rag-dataset-12000'...\n",
      "Veriseti başarıyla indirildi.\n",
      "Mevcut FAISS veritabanı yükleniyor...\n"
     ]
    }
   ],
   "source": [
    "vectorstore, texts = encode_pdf_and_get_split_documents()\n",
    "bm25 = create_bm25_index(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "729f90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Document 1 ---\n",
      "BM25 score: 38.7288\n",
      "Vector score: 0.6416\n",
      "Combined score: 0.8731\n",
      "Content: Edwin became a professional photographer quite by accident in 2003. Trained in journalism, he always thought he would become a writer, but fate landed him his first job as a photojournalist in local n...\n",
      "\n",
      "--- Document 2 ---\n",
      "BM25 score: 26.9677\n",
      "Vector score: 0.7760\n",
      "Combined score: 0.7994\n",
      "Content: Today, Edwin has a commercial portfolio but continues to pursue his documentary projects, especially long term ones that demonstrate an artistic vision on the world. Early this year, he published his ...\n",
      "\n",
      "--- Document 3 ---\n",
      "BM25 score: 22.2206\n",
      "Vector score: 0.8554\n",
      "Combined score: 0.7843\n",
      "Content: GS: What was your role in your first job at Eastern Kentucky?\n",
      "JS: I was a graduate assistant at Eastern Kentucky. I worked a lot in the weight room and then I also assisted with the defensive line ini...\n",
      "\n",
      "--- Document 4 ---\n",
      "BM25 score: 20.8394\n",
      "Vector score: 0.8223\n",
      "Combined score: 0.7473\n",
      "Content: It was in 2008 that I decided a full change of direction was required and I managed to secure myself a place on a Web Development degree at UWS. I changed to evening/weekend work at T-Mobile and start...\n",
      "\n",
      "--- Document 5 ---\n",
      "BM25 score: 20.3554\n",
      "Vector score: 0.8263\n",
      "Combined score: 0.7434\n",
      "Content: Can you talk about your service?\n",
      "I joined the United States Marine Corps after high school in 2014. I served in the Headquarters and Services Company, 2nd Battalion, 2nd Marines as a data systems admi...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the first job Edwin Koo landed in his professional career?\"\n",
    "top_docs = fusion_retrieval(vectorstore, bm25, query, k=5, alpha=0.5)\n",
    "\n",
    "for i, d in enumerate(top_docs, 1):\n",
    "    print(f\"--- Document {i} ---\")\n",
    "    print(f\"BM25 score: {d['bm25_score']:.4f}\")\n",
    "    print(f\"Vector score: {d['vector_score']:.4f}\")\n",
    "    print(f\"Combined score: {d['combined_score']:.4f}\")\n",
    "    print(f\"Content: {d['document'].page_content[:200]}...\\n\")  # ilk 200 karakter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad9518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
